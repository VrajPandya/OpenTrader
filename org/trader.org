#+title: Open Trader
#+author: Vraj Pandya
#+date:File 2023-12-25
#+STARTUP: overview
Org file for OpenTrader.

* TODO Implement Mock Fee structure
:PROPERTIES:
:VISIBILITY: content
:END:
** TODO Implement Handling Execution Details response
*** DONE Need to verify if the updates needed to the execution i.e. udating the orderID and
Execution/Entry ID are updated as expected.
*** DONE Need to verify if the Order Descriptor actually needs an update.
Yes we do need to update Order Descriptor since that will help us get the latest information into the Ledger Entry.
*** DONE Test Execution Detail response with BackTester.
*** TODO Test Execution Detail response with Gemini.

*** DONE Integrate Execution Details response in backTester.
*** DONE Implement Execution ID to OrderID and OrderID to Execution ID mapping.
*** DONE Figure out the cardinality between OrderID <=> Execution ID <=> Commission Report.
If the Cardinality between Execution ID and Commission is 1:1, Folks at IBKR are idiots or lazy or both.
WoW: https://interactivebrokers.github.io/tws-api/classIBApi_1_1Execution.html
If we expect the executions to be overridable, why do we need the commission report to be seperate?
We always attempt to get the Commission report for the latest exec ID and and will have to
assert an error in case we don't get it! It's also posssible to request all the commissions.
*** TODO Implement error assertions
*** TODO Implement error handling.
** TODO Implement Handling Commission Report
*** DONE Integrate Commission Report Generation in backTester.
*** DONE Test Commission Report Generation in backTester.
*** TODO Test Commission Report Generation with Gemini.
* TODO Implement CSV output for analysis
:PROPERTIES:
:VISIBILITY: content
:END:
** TODO Implement a Ledger Manager.
We need a Manager since we want to modularize how to write ledger.
This way it would be easy to go from CSV to OLAP or something else if need be.
** DONE Figure out a Schema for Ledger Entries and Ledger Context.
Will have to figure out Cardinality of Ledger and Entry Context data.
For now we will use 1:1 Cardinality. Worst case we might have to consider 1:Many. But that is a very special case.
All the Logic that needs to add Context will have to provide the codec for the context.
* TODO Implement Order context writing for offline analysis
** TODO Test the simple context Manager with Gemini
** TODO Test the simple context Manager with IBKR.
** DONE Implement a proper tracking mechanism for order Context and Entries.
*** DONE Figure out the interaction sequence for the context and entries.
Places where the context can be generated:
1. onFilled
2. SubmitOrder

===============================================================================================
It makes sense that when we submit the order we should have all the context we need.
So it makes sense to generate context there. So we can call SubmitOrder with this context.
The TraderLogic should be able to handle this.
We allow not generating the context by setting the default value as well.
Generating Order and Entry context at the SubmitOrder handling avoids the need of maintaining
state of the context to be transfered from the App logic to the internal state machine,
later on. This also avoids need for the App to maintain context tracking.
This also helps avoid the need to solve the concurancy problem of populating Context into the
tracking state machine.
===============================================================================================

Places where entries can finish generating:
1. onCommissionReport
2. onExecutionReport

We expect to get Context before CommissionReport. Which makes sense since we should be submitting
an order only if the context is correct and satisfied.

The Commission and the Execution Report needs to be updated once we recive it.

The order in which the Executio and the Commission Reports are updated are non deterministic.

We have to handle the concurrency problem.
i.e. We have to handle writing the context, commission report and execution report.

*** DONE add orderID feild to the EntryContext as well. Mark it non serializable.

** DONE Implement a simple context Manager.
A simple Manager which takes in Context Codecs.
*** DONE We are getting null for order ID and entry ID in all the entries.
*** DONE Resolve issue with find one and replace.
Must understand how we can correctly insert the context.
For now we can just insert the doc. No need to upsert.
** DONE Test the simple context Manager with back tester.
** DONE Implement simple codec for constant step offset
* TODO HIPRI Bugs
:PROPERTIES:
:VISIBILITY: children
:END:
** TODO Stop Tracking OrderIDs.
** TODO Test Thread safety 
** TODO State transition doesn't work as expected when the price goes below the baseline then up.
It's possible this happens on Gemini and not with IB since we have essentially multi threaded
processing for the price and the order stream.
Implemented thread safety.
* TODO Setup CLI Interface
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Publisher Side Implementation
** TODO Subscriber side Implementation
* TODO Implement pubsub
The Current two level dict lookups to find the correct logic to update the price on is a kind of a pubsub. The question is what is the level of surity we need.
Do we need process isolation between logics? So far I think we do.
** TODO Setup pulsar pubsub example
** TODO configure pulsar 
1) It has to have timeouts
2) One topic can have multiple consumers.
3) One subscription can't block other subscriptions.
4) Consumers can come online and go offline at any time.
5) message should be dequeued when the all the existing subscribers have recived the message.


* TODO Implement logic termination condition
We don't expect a logic to go on forever.
We need to be able to set some condition which logic itself can check and then decide to gracefully terminate itself.
Conditions:
1. Number of successful profit takes
2. offset from the current price to operational range.
3. Take intrupt/signal from the external interface.

* TODO Option chain
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Implement a simple option chain fetcher
** TODO Implement a simple option chain parser
** TODO Implement a simple option chain analyzer

* TODO Watchlist management
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO understand how the watch list management works? Is it a push or pull model?
** TODO Implement a demo app that fetches tickers from watch list and monitors it.



* TODO Overall Refactor
:PROPERTIES:
:VISIBILITY: children
:END:
** TODO script to shut the environment down.
** DONE Rename OrderInfo to OrderDescriptor.
=======
Need the rename soon!

* TODO Ticker/Contract profit taker spread derivation
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Implement the code to fetch the cost of putting order for a contract, i.e. trading fees.

* TODO L2 Orderbook Ingestion Infra
Should be able to track Top of the Orderbook.
Top 10 increments/decrements for ask/bid sides should be a good start.
Will have to implement seperate Infra for order Executions of ABOVE ASK/BELOW BID OFFERS.
* TODO Order What Ifs
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Implement basic logic to find the 

* TODO Account information tracking
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Positions tracking APIs to enable restoring the state of open positions when restarting the alg.
** TODO Settled Cash
** TODO Find a way to place an order without affecting logic state. Need a way to isolate order placement.
** TODO NLV fetching API call setups.
** TODO Implement Logic to find impact on NLV for an order.
* TODO Trendlines And Graph analysis
:PROPERTIES:
:VISIBILITY: folded
:END:
This is a tricky one. Will have to Really think about this. Might have to start with trend analysis for ETFs and enable drawing custom lines.
** TODO figure out a way to "draw" trendlines.
** TODO modularize trendline drawing?
We might use something like trendline to define what our maximas and minimas are?? Something that can easily help us

* TODO More Validation by syncing existing orders/Account info etc.
* TODO Pubsub Integration
Would it be benificial to write a pubsub?
Pro:
1. Multi process logic.
2. Easy management of logic because of multi processing.
Con:
1. Will have to work on it
2. latency. Need to measure/read articles.
* TODO Offline analysis
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Offline BOT analysis
** TODO Implement streaming data collection to start making granular dataset.
** TODO find 5 s Interval historical data of last 5 years at least.
** TODO hook up data backup with Onedrive/some cloud storage.
** DONE write up a simple data back up script for latest data. 
** DONE Implement modular data collection script
* TODO containerize all the process.
Since we seem to have a lot and we will have even more.
Since we need process level isolation for individual Logic 
But the primary reason to have container is to have horizontal scaling.
Containers can add a layer of security. But so far that is not our concern. Having simple OS level security is good enough for us.
* TODO Future Enhancements
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO Add support for multiple contexts per entry_id for Ledger context Manager
Currently a new context is added for an entry it's possible to add multiple context for one Entry ID.
That could be a feature or a bug. For now it's a feature. We only need to work on this if it
turns out to be a bug.
** DONE Optimize Path to update onPrice Update.
We are doing a lot of dictionary lookups. That must be Costing a TON. 
We might as well do a pubsub. Must have
** DONE OrderTracker
*** DONE Make OrderTracker Thread safe.
We use order tracking from IBKR. No need to implement something custom.
*** DONE Implement interface to data storage engine so we can track things properly.

** DONE Storage Engine
** DONE Make the interface of the storage Engine Async so we can Write stuff Async and not block stuff. 
No need for storage. As the order states are managed by IBKR and IBKR has great analysis tools.

** DONE Coroutines FTW
We had to ditch Coroutines. Coroutines somehow destabalize the IBKR API.
Also there not easy to use concurrent queues. The python implementations are also buggy. 
The Coroutines implement keyboard inturrupts and so does IBKR API.
On a personal note, I don't like that as well Coroutines implementing keyboard inturrupts.
Can't they invent some other signal handler? 
 We just need co routine powered event driven logic to power our Logic.
 That is the only way to power higher order functions/logic.
*** DONE Implement simple profit taker logic with co routines
No need for co routines just yet.
We used co routines for the telegram messaging and notification state management.
*** DONE Think about all the limits that Co routine logic Engine can have. And how to implement it.
No need for co routines just yet.
**** DONE Hop Limit (Keep Hop counter)
There is no logic hops with the updated architecture. if we need a complex logic, we implement complex state machine inside logic. Isolating logic and trade executions.
**** DONE Time Limit (Keep start timestamp)
No need. The state machine manipulations are very fast. We can only have bugs in state transitions nothing else.



* DONE Gemini Integration
** DONE Integrate Order placement REST APIs.
Rant:It's really sad that Gemini doesn't have websocket API for placing orders.
** DONE Test state machine management with Gemini!!!!
Found the problem! quick fix might be just adding a simple mutex to the logic interface.
** DONE Integrate Order event subscription websockets
** DONE Use higher frequency data stream for Gemini.
** DONE integrate Gemini price fetching API
Started with 1 minute bars. Don't need more granular info for now.
Getting Realtime socket is just too much for a start.
* DONE State machine resetting
Every Trading Logic will have to implement custom methods to store its state.
** DONE Test state machine resetting with ibkr to test the validity.
** DONE ensure the overall state saving works as expected.
** DONE Mongo needs an update/upsert/replace call not insert.
** DONE Test state machine resetting with backtesting.
** DONE find a way to serialize save the Trader logic state machine to disk.
- Most likely, we simply save everything to state machine dict variable and write a method to serialize the dict to json and back.
- We have decided to go with mongo to store the state of the trader logic.
** DONE Impliment a method to restore the state machine from disk.
** DONE write codec for state machine
* DONE Make Code sharable
:PROPERTIES:
:VISIBILITY: folded
:END:
** TODO remove all the private keys/telegram chat id from source and source tree.
** TODO remove all the things from the commit history

* DONE Data storage Interface
We will have to use the MongoDB to store all our records for orders.
** DONE Write a query interface
** DONE Setup Mongo DB locally 
** DONE Write a simple interface
** DONE Setup a seperate event queue Just like telegram
** DONE Define Entities
Good thing is IBKR already provides these entities. We just need to store them.
There are some entities that we will have to define ourselves. But 
most of them are basically a composite of the existing entities.
*** DONE Order
*** DONE Composite Order
*** DONE request session for requesting data feeds
No need for that!! ^^


* DONE Integrate State machine serialization 
** DONE Write a backtest for Gemini
Ha! what was I thinking? The backtests don't need any front end. 
** DONE Integrate mongo interface w/ backtest

* DONE Initial Implementation
:PROPERTIES:
:VISIBILITY: folded
:END:
** DONE [#B] Place a simple for profit order which reads the current value and puts a simple profit taker for $10
** DONE [#A] Implement a mechanism to register for callbacks when a specific contract gets updated.
** DONE Set simple in memory way to track the active orders/requests/seqID
** DONE Get BTC value from IBKR
** DONE Setup code to get Next Request ID


* DONE Initial Implementation of Telegram Messages
:PROPERTIES:
:VISIBILITY: folded
:END:
** DONE Use the API 
*** DONE for alerts.
*** DONE for order state changes.
** DONE [#A] Setup Telegram APIs 
** DONE [#B] Implement a Co routine based event loop execution in seperate thread.
This enabled us to enqueue the message to be sen
** DONE Write Todo a script to get chat ID of the user. 


* DONE Real time Data query/analytical engine 
:PROPERTIES:
:VISIBILITY: folded
:END:
** DONE Numpy ring buffer are the way to GO!
No NEED the trading frequency is not that high. We also have backend orders that can execute a 
dynamic algo as well that can take some of low latency needs away from us.
** DONE Implement a simple mechanism to have ring buffer like capabilities.
*** DONE Implement a triple buffer swap chain for faster analysis
No need. Simple architecture of Trader logic registering for tick updates only need to mange its state machine. The state machine management is very simple.
Since all state machine management is mathemetical non blocking operations. We are not making big predictions. Only little adjustments.
* What was I Thinking?
Of course the trading platform project becomes open comercialized and gets
converted as a product! The opertunity is, finance people are mainly motivated
by money, they must have had an offer they cannot refuse.

Once they get it, they simply change the open version to a close sourced first
open version, i.e. you have to hack really hard to get it working on your
machine such that it's just not worth it.

The oppertunity here is have a truly open Trading Engine.
** My false perception
This project so far has helped me better understand what the overall structure
to trade automatically should look like.

We only learn linked list, hash maps and graphs once. We implement simple
algorithms. We learn the basics, internalize it and then move on to using a
library implementation.

This allows us to start delivering value and reaping rewards.

I have managed to find an open source solution for algo trading.

Pro:
1. Well tested solution.
2. Lots of starts and forks with active contributions.
3. Supposed to have paying clients.
4. Option to have a well structured cloud solution.
5. Well containerized.
6. Supports C# and python.

Con:
0. Too productized! It's harder to get it working for free on my machine than
   simply developing my own engine.
1. Asking for my IBKR username password!! Hard NO!
2. There are some hooks to login which are unavoidable.
   Will have to learn to avoid those.
3. No gemini integration yet. Might have to implement my own.
4. No process isolation.
   They have primary Memory and logical isolation.
   Might have to just fork off multiple instance of the lean system
   to get process process isolation. 
5. From comments the options resolution seems to be Minutes!
   That's no Good.
   I am planning to trade options my self for a while, so shouldn't be
   a big problem. 


